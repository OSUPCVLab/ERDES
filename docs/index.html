<!DOCTYPE html>
<!-- Authors: David Ouyang, Bryan He 2019 -->
<html lang="en">
   <head>
      <meta charset="utf-8">
      <title>ERDES</title>
      <meta name="description" content="ERDES is a publicly available 3D ocular ultrasound dataset for medical AI research in retinal and macular detachment classification.">
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      <link rel="stylesheet" href="lagunita/css/bootstrap.min.css" type="text/css">
      <link rel="stylesheet" href="//netdna.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css" type="text/css">
      <link rel="stylesheet" href="lagunita/css/base.min.css?v=0.1" type="text/css">
      <link rel="stylesheet" href="lagunita/css/custom.css?v=0.1" type="text/css">
      <link rel="icon" type="image/ico" href="favicon.ico">
   </head>
   <body class="site-slogan">
      <div id="top">
         <div class="container">
            <div id="skip">
               <a href="#content" onclick="$('#content').focus()">Skip to content</a>
            </div>
         </div>
      </div>
      <div id="brandbar">
         <div class="container d-flex justify-content-between align-items-center" style="display: flex; justify-content: space-between; align-items: center;">
            <div>
               <a href="https://u.osu.edu/pcvlab/" target="_blank" style="text-decoration: none; color: white;">
                  <span style="font-weight: bold; font-size: 10px;">Photogrammetric Computer Vision Laboratory</span>
               </a>
            </div>
            <div>
               <a href="https://emergencymed.arizona.edu/" target="_blank" style="text-decoration: none; color: white;">
                  <span style="font-weight: bold; font-size: 10px;">University of Arizona Department of Emergency Medicine</span>
               </a>
            </div>
         </div>
      </div>
      <div id="header" class="clearfix" role="banner">
         <div class="container">
            <div class="row">
               <div class="col-md-8">
                  <div id="signature">
                     <div id="site-name">
                        <a href="https://osupcvlab.github.io/ERDES/"><span id="site-name-1">ERDES</span></a>
                     </div>
                     <div id="site-slogan">
                        <a href="https://osupcvlab.github.io/ERDES/">
                        <span id="site_slogan">A Benchmark Video Dataset for Retinal Detachment and Macular Status Classification in Ocular Ultrasound</span>
                        </a>
                     </div>
                  </div>
               </div>
            </div>
         </div>
      </div>
      <!-- Navigation Menu -->
      <div id="mainmenu" class="clearfix" role="navigation">
         <div class="container">
            <div class="navbar navbar-default">
               <button type="button" class="navbar-toggle btn-navbar" data-toggle="collapse" data-target=".navbar-collapse">
               <span class="menu-text">Menu</span>
               </button>
               <div class="navbar-collapse collapse">
                  <div role="navigation">
                     <div id="primary-nav">
                        <ul class="nav navbar-nav" aria-label="primary navigation">
                           <li id="nav-1"><a href="index.html">Home</a></li>
                           <li id="nav-2"><a href="index.html#intro">Introduction</a></li>
                           <li id="nav-3"><a href="index.html#motivation">Motivation</a></li>
                           <li id="nav-4"><a href="index.html#dataset">Dataset</a></li>
                           <li id="nav-5"><a href="index.html#access_dataset">Access Dataset</a></li>
                           <li id="nav-6"><a href="index.html#code">Code</a></li>
                           <li id="nav-7"><a href="index.html#paper">Paper</a></li>
                           <li id="nav-8"><a href="index.html#citation">Citation</a></li>
                        </ul>
                     </div>
                  </div>
               </div>
            </div>
         </div>
      </div>
      <!-- /Navigation Menu -->
      <div id="intro" class="container" role="introduction" tabindex="0">
         <h2>Introduction</h2>
         <p>
            Ocular ultrasonography is a fast, accessible, and non-invasive imaging tool widely utilized to assess the posterior segment of the eye, especially in the presence of media opacities like cataracts or vitreous hemorrhage.
            It plays a pivotal role in diagnosing and guiding the treatment of various retinal conditions, including retinal and macular detachment. To enable further exploration and development of computer vision techniques in this critical domain,
            we introduce <strong>E</strong>ye <strong>R</strong>etinal <strong>DE</strong>tachment Ultra<strong>S</strong>ound, <em>ERDES</em>, a comprehensive video dataset of ocular ultrasound scans. ERDES includes 5381 labeled ultrasound video clips,
            each annotated by human experts for the presence of retinal detachments (macula intact vs. detached), providing a rich resource for robust analysis of detachment patterns and classification tasks.
         </p>
         <video class="center" width="480" height="480" autoplay loop muted>
            <source src="media/output.mp4" type="video/mp4">
         </video>
         <h2 id="motivation">Motivation</h2>
         <p>
            Despite significant advances in machine learning for medical images, video-based analysis in the biomedical domain remains under-explored due to the limited availability of well-annotated medical video datasets.
            Medical videos, such as ocular ultrasound scans, are an integral part of clinical practice, yet their potential for AI-driven diagnostics and classification remains largely untapped.
            Open-access datasets have been instrumental in advancing computer vision for images; extending this collaborative environment to videos promises to accelerate progress and create robust, clinically relevant models.
            ERDES addresses this gap by offering an openly available, expertly annotated dataset of ocular ultrasound videos. We also provide baseline performance benchmarks using a 3D convolutional neural network architecture
            to detect and classify retinal and macular detachment, setting the stage for further development and collaboration in this field.
         </p>
		 <br>
		 <br>
         <h2 id="dataset">Dataset</h2>
         <p><img class="center" loading="lazy" width="640" src="media/labeling_rd.png"></p>
         <p><b>Ocular Videos:</b> The ERDES dataset comprises 5381 ocular B-scan ultrasound videos, each providing dynamic cross-sectional views of the eye's posterior segment. These videos were acquired during routine clinical care at University of Arizona between June 2010 and March 2022. 
		  To ensure patient privacy and data standardization, all videos were meticulously processed to remove any patient identifiers.
  		  Capturing both normal and pathological findings, the dataset covers a wide range of imaging scenarios, thereby offering a comprehensive resource that reflects clinical variability and supports robust analysis of retinal detachments.
         </p>
         <p><img class="center" loading="lazy" width="400" src="media/MetaDataVariables.PNG"></p>
         <p><b>Annotations:</b> Each video clip is accompanied by expert-labeled annotations indicating the presence or absence of retinal detachment along with macular involvement.
            These labels were determined by experienced sonologists following a standardized protocol. Annotations serve as a foundation for supervised learning and enable benchmarking of new computer vision approaches for video-based classification in ophthalmology.
		<p>
		  The ocular ultrasound video clips are categorized into three principal groups: 
		  <strong>Normal</strong>, 
		  <strong>Retinal Detachment (RD)</strong>, 
		  and <strong>Posterior Vitreous Detachment (PVD)</strong>. 
		  Within the <strong>Retinal Detachment</strong> category, the clips are further subdivided based on the status of the maculaâ€”specifically, whether the macula is detached or remains intact.
		</p>

		<ul>
		  <li>
			In the <strong>macula-detached</strong> subset, two types of detachments are identified:
			<ul>
			  <li><strong>Bilateral detachment</strong>, where both the nasal and temporal regions are involved.</li>
			  <li><strong>Temporal detachment (TD)</strong>, where the retinal detachment predominantly affects the temporal region of the retina.</li>
			</ul>
		  </li>
		  <li>
			In the <strong>macula-intact</strong> subset, the retinal detachment does not involve the macula, and the detachments are further divided into:
			<ul>
			  <li><strong>Nasal detachment (ND)</strong>, where the detachment involves the nasal region of the retina.</li>
			  <li><strong>Temporal detachment (TD)</strong>, where the detachment is located in the temporal region.</li>
			</ul>
		  </li>
		</ul>

		<p>
		  This structured classification helps in systematically analyzing and interpreting the retinal pathologies present in the ultrasound data. You can see the structure of dataset folders in the below figure which reflect the labeling protocol.
		  <p><img class="center" loading="lazy" width="200" src="media/folder_structure.PNG"></p>
		</p>
		 <br>
		 <br>
		  <p><b>Data Preprocessing:</b> We meticulously removed all protected health information and extraneous annotations present on the lateral sides of the ocular ultrasound clips. To achieve this, we employed a YOLO (You Only Look Once) object detection model trained specifically to identify and localize the globe of the eye within each video frame. 
		  The model was trained using a small set of manually annotated example frames, where the bounding boxes encompassed only the globe region, excluding peripheral areas that do not contribute to the diagnosis of retinal detachment. By leveraging YOLOâ€™s fast and accurate detection capabilities, we ensured that the region of interest (ROI) â€” the globe â€” was consistently identified throughout the entire clip. 
		  Subsequently, each frame in the video was cropped according to the detected bounding box, resulting in a refined dataset comprising only the relevant anatomical features for analysis.
		  All video clips in the dataset are in mp4 format, optimized for further diagnostic tasks.
         </p>
		 <p><img class="center" loading="lazy" width="840" src="media/data_stats.png"></p>
		 <br>
		 <br>
         <h2 id="access_dataset">Access Dataset</h2>
         <p>You can download the dataset using our HugginFaceðŸ¤— Dataset Card</p>
         <div class="well" id="access" tabindex="0">
            <a href="https://huggingface.co/datasets/pnavard/erdes", target="_blank">Access the ERDES dataset through this link.</a><br>
         </div>
		 <br>
		 <br>
         <h2 id="code">Code</h2>
         <p>Our code is made publically available under PCVLab's github repository <a href="https://github.com/OSUPCVLab/ERDES" target="_blank">here</a>. Please consider starring the repo.</p> 
		 <br>
		 <br>
		 <h2 id="paper">Paper</h2>
         <p><a href="https://arxiv.org/abs/2508.04735" target="_blank">ERDES: A Benchmark Video Dataset for Retinal Detachment and Macular Status Classification in Ocular Ultrasound</a><br>
            Corresponding Authord: Pouyan Navard. <b>Nature Scientific Data (Under Review)</b> (2025)
         </p>
		 <br>
		 <br>
         <h2 id="citation">Citation</h2>
         <p>Note: If you intend to use ERDES dataset in your research please cite our work using this bibliography</p>
         <pre style="background-color: #f5f5f5; border: 1px solid #ccc; padding: 10px; font-family: monospace;">
@inproceedings{navardocular,
  title={A Benchmark Dataset for Retinal Detachment Classification in Spatiotemporal Ocular Ultrasound},
  author={Navard, Pouyan and Ozkut, Yasemin and Adhikari, Srikar and Situ-LaCasse, Elaine and AcuÃ±a, Josie and Yarnish, Adrienne A and Yilmaz, Alper},
  booktitle={Nature Scientific Data (Review)},
  pages={4981--4988},
  year={2025}
}
    </pre>
		 <br>
		 <br>
		<p style="text-align:center;font-size:small;">
		  For inquiries, contact us at <a href="mailto:boreshnavard [dot] 1 [at] osu [dot] edu" target="_blank">boreshnavard [dot] 1 [at] osu [dot] edu</a>.<br>
		  Design and source code of this website was taken <a href="https://osupcvlab.github.io/ERDES/" target="_bl">from here</a>.
		</p>
         
      </div>
      <!-- Scripts -->
      <script src="//ajax.googleapis.com/ajax/libs/jquery/1.11.2/jquery.min.js"></script>
      <script src="lagunita/js/modernizr.custom.17475.js"></script>
      <script src="lagunita/js/bootstrap.min.js"></script>
      <script src="lagunita/js/base.js?v=1.0"></script>
      <script src="lagunita/js/custom.js"></script>
   </body>
</html>
